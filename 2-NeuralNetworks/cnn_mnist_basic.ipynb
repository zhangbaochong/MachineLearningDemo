{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ../Resources/mnistdata\\train-images-idx3-ubyte.gz\n",
      "Extracting ../Resources/mnistdata\\train-labels-idx1-ubyte.gz\n",
      "Extracting ../Resources/mnistdata\\t10k-images-idx3-ubyte.gz\n",
      "Extracting ../Resources/mnistdata\\t10k-labels-idx1-ubyte.gz\n",
      "(55000, 784) (55000, 10)\n",
      "(10000, 784) (10000, 10)\n"
     ]
    }
   ],
   "source": [
    "# 获得mnist数据\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "mnist = input_data.read_data_sets(\"../Resources/mnistdata\", one_hot=True)\n",
    "trainimg   = mnist.train.images\n",
    "trainlabel = mnist.train.labels\n",
    "testimg    = mnist.test.images\n",
    "testlabel  = mnist.test.labels\n",
    "print(trainimg.shape, trainlabel.shape)\n",
    "print(testimg.shape, testlabel.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义cnn\n",
    "n_input = 784\n",
    "n_output = 10\n",
    "\n",
    "weights = {\n",
    "    # 5*5 conv  1 input  32 output\n",
    "    \"wc1\" : tf.Variable(tf.random_normal([5, 5, 1, 32])),\n",
    "    # 5*5 conv  32 input  64 output\n",
    "    \"wc2\" : tf.Variable(tf.random_normal([5, 5, 32, 64])),\n",
    "    # fully connected  7*7*64 input  1024 output\n",
    "    # 原始28*28经过两个最大池化层 大小变为7*7 通道64\n",
    "    \"wd1\" : tf.Variable(tf.random_normal([7*7*64, 1024])),\n",
    "    # 1024 input 10 output\n",
    "    \"out\" : tf.Variable(tf.random_normal([1024, n_output]))\n",
    "}\n",
    "\n",
    "biases = {\n",
    "    \"bc1\" : tf.Variable(tf.random_normal([32])),\n",
    "    \"bc2\" : tf.Variable(tf.random_normal([64])),\n",
    "    \"bd1\" : tf.Variable(tf.random_normal([1024])),\n",
    "    \"out\" : tf.Variable(tf.random_normal([n_output]))\n",
    "}\n",
    "\n",
    "\n",
    "def conv2d(x, W, b, strides=1):\n",
    "    conv = tf.nn.conv2d(x, W, strides=[1, strides, strides, 1], padding='SAME')\n",
    "    conv = tf.nn.bias_add(conv, b)\n",
    "    return tf.nn.relu(conv)\n",
    "\n",
    "\n",
    "def maxpool2d(x, k=2):\n",
    "    return tf.nn.max_pool(x, ksize=[1, k, k, 1], strides=[1, k, k, 1], padding='SAME')\n",
    "\n",
    "\n",
    "def conv_net(x, weights, biases, dropout):\n",
    "    # mninst 数据类型是 1-D vector，共784features\n",
    "    # 需进行reshape\n",
    "    # Tensor input become 4-D: [Batch Size, Height, Width, Channel]  灰度图像通道数为1\n",
    "    x = tf.reshape(x, shape=[-1, 28, 28, 1])\n",
    "    # conv layer1\n",
    "    conv1 = conv2d(x, weights['wc1'], biases['bc1'])\n",
    "    # max pooling\n",
    "    conv1 = maxpool2d(conv1)\n",
    "    \n",
    "    # conv layer2\n",
    "    conv2 = conv2d(conv1, weights['wc2'], biases['bc2'])\n",
    "    # max pooling\n",
    "    conv2 = maxpool2d(conv2)\n",
    "    \n",
    "    # fully connected layer\n",
    "    # reshape get_shape()返回的是一个元组 需要转化为list\n",
    "    fc1 = tf.reshape(conv2, shape=[-1, weights['wd1'].get_shape().as_list()[0]])\n",
    "    fc1 = tf.add(tf.matmul(fc1, weights['wd1']), biases['bd1'])\n",
    "    fc1 = tf.nn.relu(fc1)\n",
    "    \n",
    "    # dropout\n",
    "    fc1 = tf.nn.dropout(fc1, dropout)\n",
    "    \n",
    "    return tf.add(tf.matmul(fc1, weights['out']), biases['out'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tf Graph input\n",
    "x = tf.placeholder(tf.float32, [None, n_input])\n",
    "y = tf.placeholder(tf.float32, [None, n_output])\n",
    "keep_prob = tf.placeholder(tf.float32)\n",
    "# params\n",
    "learning_rate = 0.001\n",
    "dropout = 0.75\n",
    "training_epochs = 200\n",
    "batch_size = 128\n",
    "display_step = 5\n",
    "\n",
    "logits = conv_net(x, weights, biases, keep_prob)\n",
    "pred = tf.nn.softmax(logits)\n",
    "# 注意tf自带交叉熵函数softmax_cross_entropy_with_logits_v2 logits对应的不是softmax或sigmoid的输出，\n",
    "# 而是softmax或sigmoid函数的输入，因为它在函数内部进行sigmoid或softmax操作。而且不能在交叉熵函数前进行softmax或sigmoid，会导致计算会出错。\n",
    "cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(logits=logits, labels=y))\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate).minimize(cost)\n",
    "\n",
    "correct_pred = tf.equal(tf.argmax(pred, 1), tf.argmax(y, 1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32))\n",
    "\n",
    "init = tf.global_variables_initializer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 000/200 cost: 2469.037028457\n",
      "TRAIN ACCURACY: 0.977\n",
      "TEST ACCURACY: 0.951\n",
      "Epoch: 005/200 cost: 53.195795324\n",
      "TRAIN ACCURACY: 0.977\n",
      "TEST ACCURACY: 0.976\n",
      "Epoch: 010/200 cost: 10.773543730\n",
      "TRAIN ACCURACY: 0.992\n",
      "TEST ACCURACY: 0.981\n",
      "Epoch: 015/200 cost: 3.630137753\n",
      "TRAIN ACCURACY: 1.000\n",
      "TEST ACCURACY: 0.983\n",
      "Epoch: 020/200 cost: 1.818905277\n",
      "TRAIN ACCURACY: 1.000\n",
      "TEST ACCURACY: 0.983\n",
      "Epoch: 025/200 cost: 0.778742206\n",
      "TRAIN ACCURACY: 1.000\n",
      "TEST ACCURACY: 0.983\n",
      "Epoch: 030/200 cost: 0.396992642\n",
      "TRAIN ACCURACY: 1.000\n",
      "TEST ACCURACY: 0.987\n",
      "Epoch: 035/200 cost: 0.337883178\n",
      "TRAIN ACCURACY: 1.000\n",
      "TEST ACCURACY: 0.986\n",
      "Epoch: 040/200 cost: 0.138674944\n",
      "TRAIN ACCURACY: 1.000\n",
      "TEST ACCURACY: 0.989\n",
      "Epoch: 045/200 cost: 0.116659934\n",
      "TRAIN ACCURACY: 1.000\n",
      "TEST ACCURACY: 0.987\n",
      "Epoch: 050/200 cost: 0.127265157\n",
      "TRAIN ACCURACY: 1.000\n",
      "TEST ACCURACY: 0.987\n",
      "Epoch: 055/200 cost: 0.283222302\n",
      "TRAIN ACCURACY: 1.000\n",
      "TEST ACCURACY: 0.988\n",
      "Epoch: 060/200 cost: 0.133101892\n",
      "TRAIN ACCURACY: 0.992\n",
      "TEST ACCURACY: 0.989\n",
      "Epoch: 065/200 cost: 0.147104908\n",
      "TRAIN ACCURACY: 1.000\n",
      "TEST ACCURACY: 0.989\n",
      "Epoch: 070/200 cost: 0.006775425\n",
      "TRAIN ACCURACY: 1.000\n",
      "TEST ACCURACY: 0.987\n",
      "Epoch: 075/200 cost: 0.054610023\n",
      "TRAIN ACCURACY: 1.000\n",
      "TEST ACCURACY: 0.991\n",
      "Epoch: 080/200 cost: 0.098504713\n",
      "TRAIN ACCURACY: 1.000\n",
      "TEST ACCURACY: 0.989\n",
      "Epoch: 085/200 cost: 0.099794348\n",
      "TRAIN ACCURACY: 1.000\n",
      "TEST ACCURACY: 0.989\n",
      "Epoch: 090/200 cost: 0.066032588\n",
      "TRAIN ACCURACY: 1.000\n",
      "TEST ACCURACY: 0.990\n",
      "Epoch: 095/200 cost: 0.003573278\n",
      "TRAIN ACCURACY: 1.000\n",
      "TEST ACCURACY: 0.989\n",
      "Epoch: 100/200 cost: 0.027409534\n",
      "TRAIN ACCURACY: 1.000\n",
      "TEST ACCURACY: 0.989\n",
      "Epoch: 105/200 cost: 0.027902563\n",
      "TRAIN ACCURACY: 1.000\n",
      "TEST ACCURACY: 0.989\n",
      "Epoch: 110/200 cost: 0.084115160\n",
      "TRAIN ACCURACY: 1.000\n",
      "TEST ACCURACY: 0.989\n",
      "Epoch: 115/200 cost: 0.045533061\n",
      "TRAIN ACCURACY: 1.000\n",
      "TEST ACCURACY: 0.989\n",
      "Epoch: 120/200 cost: 0.023778546\n",
      "TRAIN ACCURACY: 1.000\n",
      "TEST ACCURACY: 0.990\n",
      "Epoch: 125/200 cost: 0.086979250\n",
      "TRAIN ACCURACY: 1.000\n",
      "TEST ACCURACY: 0.989\n",
      "Epoch: 130/200 cost: 0.006037839\n",
      "TRAIN ACCURACY: 1.000\n",
      "TEST ACCURACY: 0.990\n",
      "Epoch: 135/200 cost: 0.005979525\n",
      "TRAIN ACCURACY: 1.000\n",
      "TEST ACCURACY: 0.989\n",
      "Epoch: 140/200 cost: 0.036353442\n",
      "TRAIN ACCURACY: 1.000\n",
      "TEST ACCURACY: 0.991\n",
      "Epoch: 145/200 cost: 0.184233398\n",
      "TRAIN ACCURACY: 1.000\n",
      "TEST ACCURACY: 0.989\n",
      "Epoch: 150/200 cost: 0.001601141\n",
      "TRAIN ACCURACY: 1.000\n",
      "TEST ACCURACY: 0.990\n",
      "Epoch: 155/200 cost: 0.017148638\n",
      "TRAIN ACCURACY: 1.000\n",
      "TEST ACCURACY: 0.990\n",
      "Epoch: 160/200 cost: 0.000000000\n",
      "TRAIN ACCURACY: 1.000\n",
      "TEST ACCURACY: 0.990\n",
      "Epoch: 165/200 cost: 0.000000000\n",
      "TRAIN ACCURACY: 1.000\n",
      "TEST ACCURACY: 0.989\n",
      "Epoch: 170/200 cost: 0.044876686\n",
      "TRAIN ACCURACY: 1.000\n",
      "TEST ACCURACY: 0.989\n",
      "Epoch: 175/200 cost: 0.003797447\n",
      "TRAIN ACCURACY: 1.000\n",
      "TEST ACCURACY: 0.991\n",
      "Epoch: 180/200 cost: 0.000480225\n",
      "TRAIN ACCURACY: 1.000\n",
      "TEST ACCURACY: 0.990\n",
      "Epoch: 185/200 cost: 0.002569630\n",
      "TRAIN ACCURACY: 1.000\n",
      "TEST ACCURACY: 0.990\n",
      "Epoch: 190/200 cost: 0.023628786\n",
      "TRAIN ACCURACY: 1.000\n",
      "TEST ACCURACY: 0.991\n",
      "Epoch: 195/200 cost: 0.030902142\n",
      "TRAIN ACCURACY: 1.000\n",
      "TEST ACCURACY: 0.990\n"
     ]
    }
   ],
   "source": [
    "# start training\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    for epoch in range(training_epochs):\n",
    "        avg_cost = 0\n",
    "        n_batch = int(mnist.train.num_examples / batch_size)\n",
    "        for i in range(n_batch):\n",
    "            batch_xs, batch_ys = mnist.train.next_batch(batch_size)\n",
    "            feeds = {x: batch_xs, y:batch_ys, keep_prob: dropout}\n",
    "            sess.run(optimizer, feed_dict=feeds)\n",
    "            feeds = {x: batch_xs, y:batch_ys, keep_prob: 1.0}\n",
    "            avg_cost += sess.run(cost, feed_dict=feeds)\n",
    "        avg_cost /= n_batch\n",
    "        \n",
    "        if epoch % display_step == 0:\n",
    "            print(\"Epoch: %03d/%03d cost: %.9f\" % (epoch, training_epochs, avg_cost))\n",
    "            train_acc = sess.run(accuracy, feed_dict={x: batch_xs, y:batch_ys, keep_prob: 1.0})\n",
    "            print(\"TRAIN ACCURACY: %.3f\" % (train_acc))\n",
    "            # 由于显卡显存限制 测试集无法一次加载 需要分批计算\n",
    "            test_acc = 0\n",
    "            n_test_batch = int(mnist.test.num_examples / batch_size)\n",
    "            for i in range(n_test_batch):\n",
    "                batch_xs, batch_ys = mnist.test.next_batch(batch_size)\n",
    "                test_acc += sess.run(accuracy, feed_dict={x: batch_xs, y: batch_ys, keep_prob: 1.0})\n",
    "            print (\"TEST ACCURACY: %.3f\" % (test_acc / n_test_batch))\n",
    "            "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
